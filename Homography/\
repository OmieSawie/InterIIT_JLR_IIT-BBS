import cv2
import numpy as np
import math
import utils as ut

img_read = cv2.imread("./ccs2Socket.jpg")

cap = cv2.VideoCapture("/dev/video2")
# cap = cv2.VideoCapture(0)

#features
sift = cv2.SIFT_create()
kp_image, desc_image = sift.detectAndCompute(img_read, None)

#make cv2 windows
cv2.namedWindow("Homography")
cv2.moveWindow("Homography", 10, 10)
cv2.namedWindow("imgC")
cv2.moveWindow("imgC", 500, 500)

# Feature matching
index_params = dict(algorithm=0, trees=5)
search_params = dict()
flann = cv2.FlannBasedMatcher(index_params, search_params)

img_gray = cv2.cvtColor(img_read, cv2.COLOR_BGR2GRAY)
img = img_read
cv2.drawKeypoints(img_gray, kp_image, img)

while True:
    _, frame = cap.read()
    if (frame is not None):

        grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        imgC = frame.copy()

        kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)
        matches = flann.knnMatch(desc_image, desc_grayframe, k=2)

        good_points = []
        for m, n in matches:
            if m.distance < 0.5 * n.distance:
                good_points.append(m)

        img3 = cv2.drawMatches(img_gray, kp_image, grayframe, kp_grayframe,
                               good_points, grayframe, 1)

        #homography
        if len(good_points) > 7:
            query_pts = np.float32([
                kp_image[m.queryIdx].pt for m in good_points
            ]).reshape(-1, 1, 2)
            train_pts = np.float32([
                kp_grayframe[m.trainIdx].pt for m in good_points
            ]).reshape(-1, 1, 2)
            matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC,
                                              5.0)

            if matrix is not None:

                ##########################################
                A = np.matrix([[476.7, 0.0, 400.0], [0.0, 476.7, 400.0],
                               [0.0, 0.0, 1.0]])
                (R, T) = ut.decHomography(A, matrix)

                Rot = ut.decRotation(R)
                zR = np.matrix([[math.cos(Rot[2]), -math.sin(Rot[2])],
                                [math.sin(Rot[2]),
                                 math.cos(Rot[2])]])
                cv2.putText(
                    imgC, 'rX: {:0.2f} rY: {:0.2f} rZ: {:0.2f}'.format(
                        Rot[0] * 180 / np.pi, Rot[1] * 180 / np.pi,
                        Rot[2] * 180 / np.pi), (20, 20),
                    cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255))
                cv2.putText(
                    imgC, 'tX: {:0.2f} tY: {:0.2f} tZ: {:0.2f}'.format(
                        T[0, 0], T[0, 1], T[0, 2]), (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255))
                pDot = np.dot((-200, -200), zR)
                red_point = (int(pDot[0, 0]), int(pDot[0, 1]))
                # cv2.circle(frame, (int(pDot[0, 0]) + train_pts[0],
                #                    int(pDot[0, 1]) + train_pts[1]), 5,
                #            (0, 0, 255), 2)

                #############################################
                # cv2.imshow("img", img)

                matches_mask = mask.ravel().tolist()

                #perspective transform
                h, w, _ = img.shape
                pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1],
                                  [w - 1, 0]]).reshape(-1, 1, 2)
                dst = cv2.perspectiveTransform(pts, matrix)

                homography = cv2.polylines(frame, [np.int32(dst)], True,
                                           (255, 0, 0), 3)

                cv2.imshow("Homography", homography)
        # else:
        # cv2.imshow("grayFrame", grayframe)

        cv2.drawKeypoints(grayframe, kp_grayframe, frame)
        cv2.imshow("img", img_gray)
        cv2.imshow("imgC", imgC)
        # cv2.imshow("Frame", frame)

        key = cv2.waitKey(1)
        if key == 27:
            break

cap.release()
cv2.destroyAllWindows()
